cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train0.py > train0.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train0.py > train0.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train0.py > train0.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train0.py > train0.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train0.py > train0.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train1.py > train1.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train1.py > train1.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train1.py > train1.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train1.py > train1.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train1.py > train1.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train2.py > train2.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train2.py > train2.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train2.py > train2.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train2.py > train2.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train2.py > train2.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train3.py > train3.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train3.py > train3.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train3.py > train3.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train3.py > train3.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train3.py > train3.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train4.py > train4.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train4.py > train4.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train4.py > train4.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train4.py > train4.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train4.py > train4.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train5.py > train5.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train5.py > train5.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train5.py > train5.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train5.py > train5.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train5.py > train5.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train6.py > train6.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train6.py > train6.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train6.py > train6.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train6.py > train6.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train6.py > train6.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train7.py > train7.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train7.py > train7.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train7.py > train7.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train7.py > train7.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train7.py > train7.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train8.py > train8.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train8.py > train8.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train8.py > train8.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train8.py > train8.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train8.py > train8.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train9.py > train9.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train9.py > train9.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train9.py > train9.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train9.py > train9.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train9.py > train9.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train10.py > train10.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train10.py > train10.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train10.py > train10.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train10.py > train10.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train10.py > train10.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train11.py > train11.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train11.py > train11.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train11.py > train11.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train11.py > train11.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train11.py > train11.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train12.py > train12.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train12.py > train12.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train12.py > train12.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train12.py > train12.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train12.py > train12.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train13.py > train13.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train13.py > train13.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train13.py > train13.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train13.py > train13.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train13.py > train13.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train14.py > train14.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train14.py > train14.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train14.py > train14.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train14.py > train14.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train14.py > train14.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train15.py > train15.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train15.py > train15.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train15.py > train15.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train15.py > train15.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train15.py > train15.txt
cd ..
cd fold0
python -m torch.distributed.launch --nproc_per_node=3 train16.py > train16.txt
cd ..
cd fold1
python -m torch.distributed.launch --nproc_per_node=3 train16.py > train16.txt
cd ..
cd fold2
python -m torch.distributed.launch --nproc_per_node=3 train16.py > train16.txt
cd ..
cd fold3
python -m torch.distributed.launch --nproc_per_node=3 train16.py > train16.txt
cd ..
cd fold4
python -m torch.distributed.launch --nproc_per_node=3 train16.py > train16.txt
cd ..
cd validation
CUDA_VISIBLE_DEVICES="1" python valid16.py > valid16.txt
cd ..
